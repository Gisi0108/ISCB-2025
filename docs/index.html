<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.57">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="dcterms.date" content="2025-08-15">

<title>Systematic review and real life-oriented evaluation on methods for feature selection in longitudinal biomedical data – ISCB 2025</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<style>

      .quarto-title-block .quarto-title-banner h1,
      .quarto-title-block .quarto-title-banner h2,
      .quarto-title-block .quarto-title-banner h3,
      .quarto-title-block .quarto-title-banner h4,
      .quarto-title-block .quarto-title-banner h5,
      .quarto-title-block .quarto-title-banner h6
      {
        color: #000000;
      }

      .quarto-title-block .quarto-title-banner {
        color: #000000;
background: #bdbdbd;
      }
</style>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="floating nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">ISCB 2025</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link active" href="./index.html" aria-current="page"> 
<span class="menu-text">Main</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default toc-left page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Systematic review and real life-oriented evaluation on methods for feature selection in longitudinal biomedical data</h1>
            <p class="subtitle lead">Methods presented at ISCB 2025</p>
                      </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Authors</div>
      <div class="quarto-title-meta-contents">
               <p>Alexander Gieswinkel (1, 2, 3), M.Sc. <a href="mailto:alexander.gieswinkel@unimedizin-mainz.de" class="quarto-title-author-email"><i class="bi bi-envelope"></i></a> <a href="https://orcid.org/0009-0004-7014-5624" class="quarto-title-author-orcid"> <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg=="></a></p>
               <p>Gregor Buch (1, 3) </p>
               <p>Gökhan Gül (1, 4) </p>
               <p>Vincent ten Cate (1, 3, 4) </p>
               <p>Lisa Hartung (2) </p>
               <p>Philipp S. Wild (1, 3, 4, 5) </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">2025-08-15</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <nav id="TOC" role="doc-toc" class="toc-active" data-toc-expanded="99">
    <h2 id="toc-title">Concepts</h2>
   
  <ul class="collapse">
  <li><a href="#gee-based-methods" id="toc-gee-based-methods" class="nav-link active" data-scroll-target="#gee-based-methods">GEE based methods</a>
  <ul class="collapse">
  <li><a href="#mathematical-backgroud" id="toc-mathematical-backgroud" class="nav-link" data-scroll-target="#mathematical-backgroud">Mathematical backgroud</a></li>
  <li><a href="#identified-software-packages" id="toc-identified-software-packages" class="nav-link" data-scroll-target="#identified-software-packages">Identified software packages</a></li>
  </ul></li>
  <li><a href="#mixed-effects-models-based-methods" id="toc-mixed-effects-models-based-methods" class="nav-link" data-scroll-target="#mixed-effects-models-based-methods">Mixed effects models based methods</a>
  <ul class="collapse">
  <li><a href="#mathematical-backgroud-1" id="toc-mathematical-backgroud-1" class="nav-link" data-scroll-target="#mathematical-backgroud-1">Mathematical backgroud</a></li>
  <li><a href="#identified-software-packages-1" id="toc-identified-software-packages-1" class="nav-link" data-scroll-target="#identified-software-packages-1">Identified software packages</a></li>
  </ul></li>
  <li><a href="#bayesian-based-methods" id="toc-bayesian-based-methods" class="nav-link" data-scroll-target="#bayesian-based-methods">Bayesian based methods</a>
  <ul class="collapse">
  <li><a href="#mathematical-backgroud-2" id="toc-mathematical-backgroud-2" class="nav-link" data-scroll-target="#mathematical-backgroud-2">Mathematical backgroud</a></li>
  <li><a href="#identified-software-packages-2" id="toc-identified-software-packages-2" class="nav-link" data-scroll-target="#identified-software-packages-2">Identified software packages</a></li>
  </ul></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references">References</a></li>
  </ul>
</nav>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar zindex-bottom">
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">





<div style="font-size: 50%;">
<p>Affiliations: 1) Preventive Cardiology and Preventive Medicine, Department of Cardiology, University Medical Center of the Johannes Gutenberg University Mainz, 55131 Mainz, Germany 2) Institute of Mathematics, Johannes Gutenberg University Mainz, 55128 Mainz, Germany 3) German Center for Cardiovascular Research (DZHK), partner site Rhine Main, 55131 Mainz, Germany 4) Clinical Epidemiology and Systems Medicine, Center for Thrombosis and Hemostasis, University Medical Center of the Johannes Gutenberg University Mainz, 55131 Mainz, Germany 5) Institute of Molecular Biology (IMB), 55131 Mainz, Germany</p>
</div>
<p>This website was created to give additional informations on the research project <a href="https://www.conftool.org/iscb2025/index.php?page=browseSessions&amp;presentations=show&amp;search=Gieswinkel">Systematic review and real life-oriented evaluation on methods for feature selection in longitudinal biomedical data</a> presented at ISCB 2025 in Basel. Non of the following is peer-reviewd, published or in a submission stage.</p>
<section id="gee-based-methods" class="level1">
<h1>GEE based methods</h1>
<section id="mathematical-backgroud" class="level2">
<h2 class="anchored" data-anchor-id="mathematical-backgroud">Mathematical backgroud</h2>
<p>The GEE (generalized estimating equations) have the following assumptions:</p>
<ul>
<li>independent measurements across the clusters (individuals)</li>
<li>measurements might correlate within clusters</li>
</ul>
<p>Details on the following concept can be found in <span class="citation" data-cites="RN19">(<a href="#ref-RN19" role="doc-biblioref">Garrett M. Fitzmaurice 2011</a>)</span>.</p>
<p>The response variables for the <span class="math inline">\(i^{\text{th}}\)</span> subject can be grouped into an <span class="math inline">\(n_i \times 1\)</span> vector <span class="math display">\[
Y_i = \begin{pmatrix}
  Y_{i1} \\ \vdots \\ Y_{in_i}
  \end{pmatrix}, \
  i = 1, \ldots , N
\]</span> (for simplicity in longitudinal cohort data: <span class="math inline">\(n_i = T\)</span> for all <span class="math inline">\(i\)</span>). Associated with each response, <span class="math inline">\(Y_{ij}\)</span> there is a <span class="math inline">\(p \times 1\)</span> vector of covariates <span class="math display">\[
X_{ij} = \begin{pmatrix}
  X_{ij1} \\ \vdots \\ X_{ijp}
  \end{pmatrix}, \
  j = 1, \ldots , T,
\]</span> which can be grouped to <span class="math display">\[
X_i = \begin{pmatrix}
  X_{i1}^T \\ \vdots \\ X_{iT}^T
  \end{pmatrix},
  = \begin{pmatrix}
  X_{i11} &amp; \dots &amp; X_{i1p} \\
  \vdots &amp; \ddots &amp; \vdots \\
  X_{iT1} &amp; \dots &amp; X_{iTp}
  \end{pmatrix}.
\]</span></p>
<p>The generalized <em>(marginal) mean model</em> for coefficients <span class="math inline">\(\beta = (\beta_1, \ldots, \beta_p)^T\)</span> is <span class="math display">\[
\begin{split}
\mathbb{E} \left[ Y_{ij} \mid X_{i} \right] = \mathbb{E} \left[ Y_{ij} \mid X_{ij} \right] &amp;= \mu_{ij} \\
g(\mu_{ij}) &amp;= \beta_0 + \beta_1 X_{ij1} + \ldots + \beta_p X_{ijp} \\
&amp;= X_{ij}^T \beta
\end{split}
\]</span></p>
<p>(with a little abuse of the notation, ignoring the intercept <span class="math inline">\(\beta_0\)</span>).</p>
<p>We assume that there exists a known ‘variance function’ <span class="math inline">\(v\)</span> and a corresponding scale parameter <span class="math inline">\(\phi\)</span> such that <span class="math display">\[
V_{ij} := \text{Var} \left[ Y_{ij} \mid X_{i} \right] = \phi v(\mu_{ij}).
\]</span></p>
<p>To adjust for the intra-class correlation structure (e.g.&nbsp;within the individuals by repeated measurements), we need more flexibility of the covariance. By setting <span class="math inline">\(A_i := \text{diag}(V_{ij})\)</span> and further <span class="math display">\[
\begin{split}
\text{Corr}\left[ Y_{ij}, Y_{ik} \mid X_{i} \right] &amp;= \varrho_{ijk}(\alpha) \\
\text{Corr} \left[Y_i \mid X_i \right] = R_i(\alpha) &amp;= (\varrho_{ijk}(\alpha))_{jk} :=  
\begin{pmatrix}
         1 &amp; \alpha_{12} &amp; \ldots &amp; \alpha_{1p} \\
         \alpha_{21} &amp; 1 &amp; \ldots &amp; \alpha_{2p} \\
         \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
         \alpha_{p1} &amp; \alpha_{p2} &amp; \dots &amp; 1
    \end{pmatrix}, \\
\end{split}
\]</span></p>
<p>we can define the <em>working covariance matrix</em> <span class="math display">\[
\text{Cov} \left[Y_i \mid X_i \right] = V_i(\alpha) := A_i^{1/2} R_i(\alpha) A_i^{1/2}.
\]</span> The parameters <span class="math inline">\(\alpha\)</span> characterizes the correlation.</p>
<p>Note: Since <span class="math inline">\(\mu_{ij} = \mu_{ij}(\beta)\)</span> is dependent on the regression coefficients, we also have <span class="math inline">\(V_i(\alpha) = V_i(\alpha, \beta)\)</span>.</p>
<p>To estimate the regression coefficients <span class="math inline">\(\beta\)</span>, we have to solve the following <strong>score equation</strong>: <span id="eq-gee"><span class="math display">\[
\begin{split}
U(\beta, \alpha) = U(\beta) :=&amp; \sum_{i=1}^N D_i^T V_i^{-1}(Y_i-\mu_i) \\
\overset{!}{=}&amp; \ 0,
\end{split}
\tag{1}\]</span></span></p>
<p>with <span class="math inline">\(D_i := \frac{\partial \mu_i}{\partial \beta}\)</span>.</p>
<p>Note: In the Gaussian case, i.e.&nbsp;<span class="math inline">\(g(\mu_{ij}) = \mu_{ij}\)</span>, we have <span class="math inline">\(\frac{\partial \mu_i}{\partial \beta} = X_i\)</span>. Additional, when writing <span class="math inline">\(g(\mu_{ij}) =: \eta_{ij}\)</span> in the general case we get <span class="math inline">\(\frac{\partial \mu_i}{\partial \beta} = \frac{\partial \mu_i}{\partial \eta_{i}} X_i\)</span></p>
</section>
<section id="identified-software-packages" class="level2">
<h2 class="anchored" data-anchor-id="identified-software-packages">Identified software packages</h2>
<p>These identified R packages are based on the GEE framework.</p>
<section id="pgee-not-selected" class="level3">
<h3 class="anchored" data-anchor-id="pgee-not-selected">PGEE [not selected]</h3>
<p><strong>PGEE</strong> does not provide a default threshold to decide if a variable is selected or not. Therefore it was excluded from the methods during screening. But since most of the following GEE-based packages relies on this method, it is usefull to present it’s approach at the beginning of this section:</p>
<p>The R package <strong>PGEE</strong> <span class="citation" data-cites="RN16">(<a href="#ref-RN16" role="doc-biblioref">Wang, Zhou, and Qu 2012</a>)</span> adds a penalty term to the <a href="#eq-gee" class="quarto-xref">score equation&nbsp;1</a>. More precisely, the SCAD (smoothly clipped absolute deviation) penalty is chosen: <span class="math display">\[
q_{\lambda}(\theta) := \lambda \left(
  1_{\theta \leq \lambda} +
  \frac{(a \lambda - \theta)_+}{(a-1)\lambda} 1_{\theta &gt; \lambda} \right)
\]</span> Where <span class="math inline">\(\theta \geq 0\)</span>, <span class="math inline">\(a &gt; 2\)</span> (set to <span class="math inline">\(a=3.7\)</span>). The penalized regression coefficients can be calculated by solving the modified equation: <span id="eq-pgee"><span class="math display">\[
\begin{split}
U^\text{PGEE}(\beta) :=&amp; \ U(\beta) - q_\lambda(|\beta|) \circ \text{sign}(\beta)  \\
\overset{!}{=}&amp; \ 0,
\end{split}
\tag{2}\]</span></span> where <span class="math inline">\(\circ\)</span> denotes the Hadamard product (element-wise product) of two vectors.</p>
</section>
<section id="lassogee" class="level3">
<h3 class="anchored" data-anchor-id="lassogee">LassoGEE</h3>
<p>No references were found for this package. However, checking the code of the main functions revealed the direct usage of the <strong>PGEE</strong> functions, but own functions to include the <span class="math inline">\(L^1\)</span>-penalty were additionally included.</p>
</section>
<section id="pgee.mixed" class="level3">
<h3 class="anchored" data-anchor-id="pgee.mixed">pgee.mixed</h3>
<p>Reference paper is <span class="citation" data-cites="RN24">(<a href="#ref-RN24" role="doc-biblioref">Deshpande, Dey, and Schifano 2019</a>)</span> Can be applied for multivariate outcomes and is for the univariate case the same as <strong>PGEE</strong>. There is an additional method for controlling the FDR of the selection, but this is (currently) only in the multivariate setting available.</p>
</section>
<section id="geeverse" class="level3">
<h3 class="anchored" data-anchor-id="geeverse">geeVerse</h3>
<p>The R package <strong>geeVerse</strong> <span class="citation" data-cites="RN14">(<a href="#ref-RN14" role="doc-biblioref">Zu et al. 2022</a>)</span> is based on <strong>PGEE</strong> but uses a <em>quantile</em> regression approach, i.e.&nbsp;for a given quantile <span class="math inline">\(\tau \in (0,1)\)</span> we consider <span class="math display">\[
\theta_\tau(Y_i \mid X_i) = X_i \beta_\tau
\]</span> with different regression coefficients <span class="math inline">\(\beta_\tau (=: \beta)\)</span> at different quantile levels. Instead of using <span class="math inline">\(U(\beta)\)</span>, we have to adjust this a bit: <span class="math display">\[
\tilde{U}(\beta) :=  \sum_{i=1}^N X_i^T \Gamma_i R_i^{-1}(\tau - 1_{Y_i \leq X_i\beta}),
\]</span> where <span class="math inline">\(\Gamma_i\)</span> is a <span class="math inline">\(T \times T\)</span> diagonal matrix of the conditional density of error <span class="math inline">\(Y_{ij} - X_{ij}\beta\)</span> and <span class="math inline">\(\tau - 1_{Y_i \leq X_i\beta}\)</span> is seen component wise.</p>
<p>The corresponding quantile penalized generalized estimating equation is then defined as <span id="eq-geeverse"><span class="math display">\[
\begin{split}
U^\text{geeVerse}(\beta) :=&amp; \ \tilde{U}(\beta) - q_\lambda(|\beta|) \circ \text{sign}(\beta)  \\
\overset{!}{=}&amp; \ 0.
\end{split}
\tag{3}\]</span></span></p>
</section>
<section id="sgee" class="level3">
<h3 class="anchored" data-anchor-id="sgee">sgee</h3>
<p>The package <strong>sgee</strong> <span class="citation" data-cites="RN18">(<a href="#ref-RN18" role="doc-biblioref">Vaughan et al. 2017</a>)</span> builds a model via a <em>stagewise</em> procedure: Start with a null model, i.e.&nbsp;<span class="math inline">\(\beta^{[0]} := 0\)</span> and update this to <span class="math inline">\(\beta^{[t]} := \beta^{[t-1]} + \delta^{[t]}\)</span>, <span class="math inline">\(t \in \mathbb{N}\)</span>. In the general framework, the update increment is defined as <span class="math display">\[
\begin{split}
\delta^{[t]} :=&amp; \ \underset{\delta \in \mathbb{R}^p}{\mathrm{arg\min}}
  f(\beta^{[t-1]} + \delta) - f(\beta^{[t-1]}) \\
  &amp; \text{subject to} \ \phi(\beta^{[t-1]} + \delta) - \phi(\beta^{[t-1]}) \leq \varepsilon,
\end{split}
\]</span> where <span class="math inline">\(\varepsilon &gt; 0\)</span> is the step size and <span class="math inline">\(\phi\)</span> the penalty function (which satisfies the triangular inequality - in our case it’s the LASSO penalty <span class="math inline">\(\phi(\delta) = \lVert \delta \rVert_1\)</span>). Via Taylor expansion, one can approximate the general framework to <span class="math display">\[
\delta^{[t]} = \underset{\delta \in \mathbb{R}^p}{\mathrm{arg\min}}
\langle \nabla f(\beta^{[t-1]}) , \delta \rangle \ \text{subject to} \ \phi(\delta) \leq \varepsilon.
\]</span></p>
<p>To merge the <a href="#eq-gee" class="quarto-xref">GEE approach&nbsp;1</a> to this structure, we interpret <span class="math inline">\(U(\beta, \nu) = \nabla f(\beta, \nu)\)</span>, where the nuisance parameters <span class="math inline">\(\nu = (\beta_0, \psi, \alpha)\)</span> contains information about the intercept <span class="math inline">\(\beta_0\)</span>, the dispersion <span class="math inline">\(\psi\)</span> and the intra-correlation structure <span class="math inline">\(\alpha\)</span>. The stagewise procedure starts then also with <span class="math inline">\(\beta^{[0]} = 0\)</span> and updates to</p>
<p><span class="math display">\[
\begin{split}
i) &amp; \ \text{Given} \ \beta^{[t-1]}, \ \text{update the nuisance parameters to obtain} \ \nu^{[t]} \\
ii) &amp; \ \delta^{[t]} = \underset{\delta \in \mathbb{R}^p}{\mathrm{arg\min}}
      \langle U(\beta^{[t-1]}, \nu^{[t]}) , \delta \rangle \
      \text{subject to} \ \phi(\delta) \leq \varepsilon, \\
iii) &amp; \ \beta^{[t]} = \beta^{[t-1]} + \delta^{[t]}.
\end{split}
\]</span></p>
<p>Note: In <span class="citation" data-cites="RN18">(<a href="#ref-RN18" role="doc-biblioref">Vaughan et al. 2017</a>)</span>, the procedure is generalized for the bi-level setting using the group LASSO (gLASSO) penalty.</p>
</section>
</section>
</section>
<section id="mixed-effects-models-based-methods" class="level1">
<h1>Mixed effects models based methods</h1>
<section id="mathematical-backgroud-1" class="level2">
<h2 class="anchored" data-anchor-id="mathematical-backgroud-1">Mathematical backgroud</h2>
<p>In contrast to the approach via a marginal model (GEE), the mixed effects models are based on the assumption of heterogeneity across the individuals in some predictor variables. Using the same notation as above, we introduce a sub-matrix <span class="math inline">\(Z_i \leq X_i\)</span>, i.e.&nbsp;all columns of <span class="math inline">\(Z_i\)</span> are columns of <span class="math inline">\(X_i\)</span>. Given a collection of additional coefficients <span class="math inline">\(b_i \sim N(0,G)\)</span> and some errors <span class="math inline">\(\varepsilon_i \sim N(0,\sigma^2I_T)\)</span> for each subject <span class="math inline">\(i\)</span> (all independent of the predictors <span class="math inline">\(X\)</span>), we can write</p>
<p><span class="math display">\[
Y_i = X_i^T \beta + Z_i^T b_i + \varepsilon_i.
\]</span> The regression is now formulated as</p>
<p><span class="math display">\[
\mu_{ij} := E[Y_{ij} \mid b_i] = X_{ij}^T \beta + Z_{ij}^T b_i,
\]</span></p>
<p>where <span class="math inline">\(\beta\)</span> is interpreted as <em>fixed effects</em> and <span class="math inline">\(b_i\)</span> as <em>random effects</em>.</p>
<p>The generalized mixed effects are therefore given by</p>
<p><span id="eq-glmm"><span class="math display">\[
\eta_{ij} := g(E[Y_{ij} \mid b_i]) = X_{ij}^T \beta + Z_{ij}^T b_i.
\tag{4}\]</span></span></p>
<p>The term <span class="math inline">\(X_{ij}^T\beta\)</span> can be seen as difference from the population mean and the additional term <span class="math inline">\(Z_{ij}^Tb_i\)</span> accounts the subject-specific effect. Therefore, the <span class="math inline">\(b_i\)</span> introduces a correlation structure (marginally) between the <span class="math inline">\(Y_i\)</span>.</p>
<p>Note: As usual, <span class="math inline">\((\mu_{ij})_j\)</span> are independent and belong to the exponential family with <span class="math inline">\(\text{Var} [\mu_{ij}] = \phi v(\mu_{ij})\)</span> for a variance function <span class="math inline">\(v\)</span> and a dispersion parameter <span class="math inline">\(\phi\)</span>.</p>
<p>A common procedure to solve the regression formula for mixed effects models is via maximum likelihood estimation. The basis assumptions implies that <span class="math inline">\(Y_i | b_i\)</span> has an exponential family distribution and <span class="math inline">\(b_i\)</span> has a multivariate normal distribution with zero mean and covariance matrix <span class="math inline">\(G\)</span>. The (integrated) likelihood function is then defined as <span class="math display">\[
L(\beta, \phi, G) = \prod_{i=1} ^N\int f(Y_i|b_i; \phi) f(b_i; G) \ \text{d}b_i.
\]</span> Therefore, the likelihood depends on the covariance of <span class="math inline">\(b_i\)</span>, but not on the unobserved <span class="math inline">\(b_i\)</span>. More details can be found in <span class="citation" data-cites="RN19">(<a href="#ref-RN19" role="doc-biblioref">Garrett M. Fitzmaurice 2011</a>)</span>.</p>
<p>As usual, the lowercase <span class="math inline">\(\ell\)</span> denotes the log-likelihood function. Since the above integral has no closed form, a numerical solution to the (log-)likelihood function is often computed via an approximation of the integrand. This is the so-called <em>penalized quasi-likelihood</em> (PQL): <span class="math display">\[
\ell^{\text{PQL}}(\beta, \phi, G) := \sum_{i=1}^N \log\big(f(Y_i|b_i)\big) - \frac{1}{2}b^TGb.
\]</span></p>
</section>
<section id="identified-software-packages-1" class="level2">
<h2 class="anchored" data-anchor-id="identified-software-packages-1">Identified software packages</h2>
<p>The following identified R packages are based on the GLMM (genealized linear mixed effects model) framework.</p>
<section id="glmmlasso" class="level3">
<h3 class="anchored" data-anchor-id="glmmlasso">glmmLasso</h3>
<p><span class="citation" data-cites="groll2012">(<a href="#ref-groll2012" role="doc-biblioref">Groll and Tutz 2012</a>)</span> expanded the PQL by an additional penalty term for the fixed effects, motivated by the LASSO regularization: <span class="math display">\[
\ell^{\text{glmmLasso}}(\beta, \phi, G) := \ell^{\text{PQL}}(\beta, \phi, G) - \lambda \lVert \beta \rVert_1,
\]</span> where the <span class="math inline">\(\text{argmax} \ \ell^{\text{glmmLasso}}(\beta, \phi, G)\)</span> will preserve the estimates for <span class="math inline">\(\beta\)</span> and <span class="math inline">\(b\)</span>.</p>
<p>But since there is no default setting for the penalty parameter <span class="math inline">\(\lambda\)</span>, nor a default setting for the grid.</p>
</section>
<section id="rpql" class="level3">
<h3 class="anchored" data-anchor-id="rpql">rpql</h3>
<p><span class="citation" data-cites="hui2017">(<a href="#ref-hui2017" role="doc-biblioref">Hui, Müller, and Welsh 2017</a>)</span> built up a similar framework, by subtracting additional terms from the PQL: <span class="math display">\[
\ell^{\text{rpql}}(\beta, \phi, G) := \ell^{\text{PQL}}(\beta, \phi, G) - \lambda\sum_{p' = 1}^pv_{p'}|\beta_{p'}| - \lambda \sum_{q'=1}^q w_{q'}\lVert b_{\bullet q'} \rVert_2,
\]</span> where <span class="math inline">\(v_{p'}\)</span> and <span class="math inline">\(w_{q'}\)</span> are weights analogous to the adaptive (group) LASSO (i.e.&nbsp;the reciprocal of the OLS) . The coefficients are then also estimated by <span class="math inline">\(\text{argmax} \ \ell^{\text{rpql}}(\beta, \phi, G)\)</span>.</p>
</section>
<section id="splmm" class="level3">
<h3 class="anchored" data-anchor-id="splmm">splmm</h3>
<p>The idea of the approach of <span class="citation" data-cites="yang2022">(<a href="#ref-yang2022" role="doc-biblioref">Yang and Wu 2022</a>)</span> is to penalize both fixed and random effects. To penalize the random effects, the correlation matrix must be considered: Rewrite <span class="math inline">\(G = \sigma^2 D\)</span> and apply the Cholesky decomposition <span class="math inline">\(D = LL^T\)</span>. The advantage of this decomposition is that now the <span class="math inline">\(k\)</span>-th row of <span class="math inline">\(L\)</span> (<span class="math inline">\(L_{(k)}\)</span>) is linked to the <span class="math inline">\(k\)</span>-th random effect, i.e.&nbsp;if <span class="math inline">\(L_{(k)} = 0\)</span>, the <span class="math inline">\(k\)</span>-th random effect will be removed from the model. A similar approximation is done to simplify the likelihood function and in addition, the nuisance <span class="math inline">\(\phi\)</span> is substituted leading to the <em>profile log-likelihood</em> <span class="math display">\[
\ell^{\text{PL}}(\beta, D) := \frac{1}{2} \sum_{i=1}^N \log|V_i| + \frac{N}{2}\log\Big(\sum_{i=1}^N (Y_i - X_i\beta)^T V_i^{-1} (Y_i - X_i\beta) \Big),
\]</span> with <span class="math inline">\(V_i := Z_iDZ_i^T + I_T\)</span> the (standardized) conditional covariance matrix of <span class="math inline">\(Y_i\)</span>. Extending this with two simultaneous applied penalties leads to the final objective function: <span class="math display">\[
\ell^{\text{splmm}}(\beta, D) := \ell^{\text{PL}}(\beta, D) + \sum_{p'=1}^p P_{\lambda_1}(|\beta_{p'}|) + \sum_{q'=2}^q P_{\lambda_2}(\lVert L_{(k)} \rVert_2).
\]</span> The first penalty function, <span class="math inline">\(P_{\lambda_1}\)</span> regulates the sparsity of <span class="math inline">\(\beta\)</span>, while <span class="math inline">\(P_{\lambda_2}\)</span> regulates the sparsity of the random effects (via sparsity of <span class="math inline">\(L\)</span>). Starting at <span class="math inline">\(q' = 2\)</span> ensures to keep the random intercept in the model.</p>
<p>Note: <span class="math inline">\(P_{\lambda_2}\)</span> introduces a group penalty on the rows of <span class="math inline">\(L\)</span>, achieving the shrinkage of all entries of a certain row to <span class="math inline">\(0\)</span>.</p>
<p>The <strong>splmm</strong> package currently supports the LASSO and SCAD (default setting) penalties as independent choices for <span class="math inline">\(P_{\lambda_k}\)</span>.</p>
</section>
<section id="plsmmlasso" class="level3">
<h3 class="anchored" data-anchor-id="plsmmlasso">plsmmLasso</h3>
<p>To understand this method, we first have to introduce GSMM (Generalized Semiparametric Mixed Models) <span class="citation" data-cites="taavoni2021">(<a href="#ref-taavoni2021" role="doc-biblioref">Taavoni and Arashi 2021</a>)</span>: <span class="math display">\[
\eta_{ij}^{\text{GSMM}} := X_{ij}^T \beta + Z_{ij}^T b_i + f(t_{ij}),
\]</span> where <span class="math inline">\(t_{ij}\)</span> is the time point of the <span class="math inline">\(j\)</span>-th measurement of subject <span class="math inline">\(i\)</span> and <span class="math inline">\(f\)</span> a continuous and twice differentiable function on some finite interval. The unspecified function <span class="math inline">\(f\)</span> is approximated via <span class="math display">\[
\begin{split}
f(t_{ij}) &amp;= a_0 + a_1 t_{ij} + \ldots + a_d t_{ij}^d + \sum_{\ell=1}^L a_{d+1+\ell}(t_{ij}-t_i^{(\ell)})_+^d \\
&amp;= B(t_{ij})^T a,
\end{split}
\]</span> expressed by the scalar product of basis functions <span class="math inline">\(B(t_{ij})\)</span> and spline coefficients <span class="math inline">\(a\)</span>. Defining <span class="math inline">\(D_{ij} := (X_{ij}^T, B_j(t_{ij})^T)^T\)</span> and <span class="math inline">\(\theta := (\beta^T, a^T)^T\)</span>, the equation for GSMM can be rewritten as <span class="math display">\[
\eta_{ij}^{\text{GSMM}} = D_{ij}^T\theta + Z_{ij}^Tb_i.
\]</span> The corresponding log-likelihood function is then expanded by a penalty term, yielding to <span class="math display">\[
\ell^{\text{plsmmLasso}}(\beta, a, D, \phi) := \sum_{i=1}^N \log\big(p_{Y_i|b_i}(Y_i|b_i, \theta)\big) + \sum_{i=1}^N \log\big(p_{b_i}(b_i)\big) - n \sum_{p' = 1}^p P_{\lambda}(|\beta_{p'}|)
\]</span> with a penalty function <span class="math inline">\(P_\lambda\)</span> (e.g.&nbsp;SCAD) and tuning parameter <span class="math inline">\(\lambda\)</span>.</p>
<p>Note: The second term is not necessary for the estimation of the coefficients <span class="math inline">\(\beta\)</span>.</p>
<p><strong>plsmmLasso</strong> does perform a <em>partial linear semiparametric mixed effects model</em>, but there is no further information about this specific approach.</p>
</section>
<section id="alqrfe" class="level3">
<h3 class="anchored" data-anchor-id="alqrfe">alqrfe</h3>
<p>The package is based on a penalized quantile regression approach <span class="citation" data-cites="danilevicz2024">(<a href="#ref-danilevicz2024" role="doc-biblioref">Danilevicz, Reisen, and Bondon 2024</a>)</span>. Only the random intercepts are included next to the fixed effects in this model, e.g.&nbsp;we assume <span class="math display">\[
Y_{ij} = X_{ij}^T \beta + b_i + \varepsilon_{ij}.
\]</span> More precisely, this approach models the <span class="math inline">\(\tau\)</span>-quantile of <span class="math inline">\(Y_{ij}\)</span> given <span class="math inline">\(X_{ij}\)</span>: <span class="math display">\[
Q_{Y_{ij}}(\tau|X_{ij}) = X_{ij}^T \beta(\tau) + b_i(\tau).
\]</span> To express the estimation approach, we need some definitions. For <span class="math inline">\(u \in \mathbb{R}\)</span>, let <span class="math inline">\(\psi_\tau(u) := |\tau - 1_{u \leq 0}|\)</span>, <span class="math inline">\(g(\cdot)\)</span> a convex loss function and <span class="math inline">\(\varrho_\tau(u) := \psi_\tau(u)g(u)\)</span>.</p>
<p>Possible choices for <span class="math inline">\(g\)</span> are: <span class="math display">\[
\begin{split}
1) &amp; \ g_1(u) := |u|, \\
&amp; \ \text{quantile regression with fixed effects (QRFE)}; \\
2) &amp; \ g_2(u) := u^2, \\
&amp; \ \text{expectile regression with fixed effects (ERFE)}; \\
3) &amp; \ g_3(u) := \Big(c|u| - \frac{1}{2}c^2 \Big) 1_{|u| &gt; c} + \Big(\frac{1}{2} u^2 \Big) 1_{|u| \leq c}, \ c&gt;0, \\
&amp; \ \text{M-quantile regression with fixed effects (MQRFE)}.
\end{split}
\]</span> Note: <span class="math inline">\(g_3\)</span> is the so-called Huber loss function and is a robust mixture of <span class="math inline">\(g_1\)</span> and <span class="math inline">\(g_2\)</span>.</p>
<p>Taking account of a LASSO-like penalty term, weighted by a tuning parameter <span class="math inline">\(\lambda\)</span>, resolves in following equation and will be used to estimate the regression coefficients:</p>
<p><span class="math display">\[
\min_{b \in \mathbb{R}^N, \\ \beta \in \mathbb{R}^p} \sum_{i=1}^N \sum_{j=1}^T \varrho_\tau(Y_{ij} - X_{ij}^T\beta - b_i) + \lambda \sum_{i=1}^N|b_i|.
\]</span></p>
<p>The <strong>alqrfe</strong> package calculates <span class="math inline">\(\lambda\)</span> via a grid within the main function <em>qr</em>. There, the method ‘lqrfe’ (‘l’ for LASSO) relates to above expression, but there is also the ‘adaptive’ variant of it, ‘alqrfe’, using solution of QRFE as weights for ‘lqrfe’. But there is no further literature about this and it is unclear, which <span class="math inline">\(g\)</span> is used (most likely <span class="math inline">\(g_1\)</span> for LASSO).</p>
</section>
<section id="buildmer" class="level3">
<h3 class="anchored" data-anchor-id="buildmer">buildmer</h3>
<p>There is no peer-reviewed publication for this package, even though it is the most frequently used package in this review (<span class="math inline">\(&gt; 170,000\)</span> all-time downloads). Only a <a href="https://cran.r-project.org/web/packages/buildmer/vignettes/buildmer.html">vignette</a> is revealing details on this method. The core idea is ‘finding the maximal <em>feasible</em> model &amp; doing stepwise elimination from it’.</p>
<p>This algorithm is also available for the frameworks of Generalized Additive Models (GAM) and Mixed-Effects-Regression Trees (MERT).</p>
</section>
</section>
</section>
<section id="bayesian-based-methods" class="level1">
<h1>Bayesian based methods</h1>
<section id="mathematical-backgroud-2" class="level2">
<h2 class="anchored" data-anchor-id="mathematical-backgroud-2">Mathematical backgroud</h2>
<p>Assume a regression model with <span class="math inline">\(p\)</span> independent predictors <span class="math display">\[
Y \mid X, \beta, \sigma^2 \sim \mathcal{N}(X^T\beta, \sigma^2I).
\]</span> We have to find the posterior distribution to <span class="math inline">\(\beta\)</span> which needs to provide a rationale to decide wether a variable <span class="math inline">\(X_i\)</span> is included in the final model or not. The two R packages <em>sparsereg</em> and <em>spikeSlabGAM</em> are based on two different approaches to model the distribution of <span class="math inline">\(\beta\)</span>. The first one extens the Bayesian LASSO apporoach while the secound one applies the SSVS / spike-and-slab framework to the GAMM (generalized additive mixed model).</p>
<section id="the-oracle-property" class="level3">
<h3 class="anchored" data-anchor-id="the-oracle-property">The Oracle Property</h3>
<p>Assume a model <span class="math inline">\(Y_i = X_i^T\beta + \varepsilon_i\)</span> with centered errors <span class="math inline">\(\varepsilon_i\)</span> that have finite fourth moments and a set <span class="math inline">\(S := \lbrace k \mid \beta_k \neq 0 \rbrace\)</span> of the incices of the <em>in-truth nonzero</em> eintries of <span class="math inline">\(\beta\)</span>. An <em>oracle estimator</em> <span class="math inline">\(\hat{\beta}^\text{oracle}\)</span> satisfies <span class="math display">\[
\begin{split}
1) &amp; \ \text{Consistent variable selection, i.e. } \lim\limits_{N \rightarrow \infty} \lbrace k \mid \hat{\beta}^\text{oracle} \neq 0 \rbrace = S \\
2) &amp; \ \text{Optimale estimation rate, i.e. } \sqrt{N}\left(\hat{\beta}^\text{oracle}_S - \beta_S\right) \xrightarrow{\text{d}} \mathcal{N}(0_{|S|}, \Sigma^*_S), \\
&amp; \ \text{with } \Sigma^*_S \text{ the asymptotic covariance matrix from the true subset model}
\end{split}
\]</span></p>
<p>For example, the adaptive LASSO (frequentist approach) satisfies the Oracle Property.</p>
</section>
<section id="spike-slab-regression" class="level3">
<h3 class="anchored" data-anchor-id="spike-slab-regression">Spike &amp; Slab regression</h3>
<p>See <span class="citation" data-cites="Dab2019">(<a href="#ref-Dab2019" role="doc-biblioref">Dablander 2019</a>)</span> and <span class="citation" data-cites="PN2015">(<a href="#ref-PN2015" role="doc-biblioref">Perrakis and Ntzoufras 2015</a>)</span> for further insights of this subsection. Set <span class="math display">\[
\beta_i \sim (1-\pi_i)\delta_0 + \pi_i \mathcal{N}(0, \sigma^2 \tau^2), \ i = 1,\ldots,p
\]</span> with <span class="math inline">\(\pi_i \in [0,1]\)</span> a mixture weight, <span class="math inline">\(\sigma^2\)</span> the error variance, <span class="math inline">\(\delta_0\)</span> the Dirac delta function with mass on <span class="math inline">\(0\)</span> (this is corresponding as the <em>spike</em>) and <span class="math inline">\(\tau^2\)</span> the variance of the so-called <em>slab</em>. In fact, the above structure is hierachical, i.e.&nbsp;there are additional prior assumptions: <span class="math display">\[
\begin{split}
\pi &amp;\sim \text{Ber}(\theta) \\
\theta &amp;\sim \text{Beta}(a,b) \\
\sigma^2 &amp;\sim \Gamma^{-1}(\alpha_1, \alpha_2) \\
\tau^2 &amp;\sim \Gamma^{-1}\left(\frac{1}{2}, \frac{s^2}{2} \right)
\end{split}
\]</span> To ‘solve’ this system, the Gibbs sampler is used. Therefore, we need the posterior distributions of the conditional hyperparameters. It turns out that <span class="math inline">\(\pi \mid \beta, \tau^2, \theta\)</span> is computationally problematic due to the Dirac function. A solution to this is to replace the Dirac function by a centered normal distribution with very less variance. This is know as</p>
</section>
<section id="ssvs-stochastic-search-variable-selection" class="level3">
<h3 class="anchored" data-anchor-id="ssvs-stochastic-search-variable-selection">SSVS (stochastic search variable selection)</h3>
<p>In this approach, a coefficient won’t be set to exactally <span class="math inline">\(0\)</span>, but a priori to a very ‘small’ area around <span class="math inline">\(0\)</span>. To be precise, we assume <span class="math display">\[
\beta_i \mid \gamma_i \sim (1-\gamma_i)\mathcal{N}(0, \tau_i^2) + \gamma_i \mathcal{N}(0, \tau_i^2c_i^2)
\]</span> with <span class="math inline">\(\mathbb{P}(\gamma_i = 1) = 1- \mathbb{P}(\gamma = 0) = \pi_i\)</span> from the above section, <span class="math inline">\(\tau_i^2\)</span> ‘small’ and <span class="math inline">\(\tau_i^2c_i^2\)</span> ‘large’ in comparison.</p>
<p>Note: It is assumed that the <span class="math inline">\(\gamma_i\)</span>s are independent, i.e. <span class="math display">\[
\pi(\gamma) = \prod_{i=1}^p \pi_i^{\gamma_i} (1-\pi_i)^{(1-\gamma_i)}.
\]</span> This means that the inclusion of feature <span class="math inline">\(X_{\ell}\)</span> is independent of the inclusion of <span class="math inline">\(X_{\ell'}\)</span> for all <span class="math inline">\(\ell \neq \ell'\)</span>.</p>
<p>The output of the SSVS is the posterior sample <span class="math inline">\(\lbrace \beta^{(t)}, \sigma^{(t)}, \gamma^{(t)} \rbrace_{t=1}^T\)</span>, where <span class="math inline">\(t\)</span> indicates the iteration. The estimated inclusion probability of a feature <span class="math inline">\(X_i\)</span> can be obtained by <span class="math display">\[
\hat{\mathbb{P}}(\gamma_i = 1 \mid Y) = \frac{1}{T}\sum_{t=1}^T\gamma_i^{(t)}.
\]</span></p>
</section>
</section>
<section id="identified-software-packages-2" class="level2">
<h2 class="anchored" data-anchor-id="identified-software-packages-2">Identified software packages</h2>
<p>The following selected R packages are based on Bayesian frameworks.</p>
<section id="sparsereg" class="level3">
<h3 class="anchored" data-anchor-id="sparsereg">sparsereg</h3>
<p>The underlying Bayesian method is called <em>LASSOplus</em> and is first described in <span class="citation" data-cites="ratkovic2017">(<a href="#ref-ratkovic2017" role="doc-biblioref">Ratkovic and Tingley 2017</a>)</span>. The frequentist LASSO approach can be interpreted in the Bayesian framework as the MAP (maximum a perstiori) estimate of a certain model. Using a <em>double-exponential prior</em> <span class="math inline">\(\mathbb{P}(\beta_j \mid \lambda) = \frac{1}{2\lambda} \exp(-\lambda | \beta_j |) =: DE(\lambda)\)</span>, the Bayesian LASSO can be written as <span class="math display">\[
\begin{split}
Y_i \mid X_i, \beta, \sigma^2 &amp;\sim \mathcal{N}(X_i^T\beta, \sigma^2) \\
\beta_k \mid \lambda, \sigma^2 &amp;\sim DE\left(\frac{\lambda}{\sigma}\right) \\
\lambda^2 &amp;\sim \Gamma(\delta, \rho)
\end{split}
\]</span></p>
<p>Extending this model, LASSOplus can be written as hierachical prior model <span class="math display">\[
\begin{split}
Y_i | X_i, \beta, \sigma^2 &amp;\sim \mathcal{N}(X_i^T\beta, \sigma^2) \\
\beta_k | \lambda, w_k, \sigma^2 &amp;\sim DE\left(\frac{\lambda w_k}{\sigma}\right) \\
\lambda^2 |  N, K &amp;\sim \Gamma\left(K(\sqrt{N}-1), \rho\right) \\
w_k | \gamma &amp;\sim \text{generalized Gamma}(1,1,\gamma) \\
\gamma &amp;\sim \exp(1)
\end{split}
\]</span></p>
<p>The LASSOplus estimate is constructed from the estimate <span class="math inline">\(\beta_k\)</span> and a thresholding (described by an <em>inflated variance component</em> <span class="math inline">\(\sigma_{sp}^2\)</span>) that zeroes out sufficently small values of <span class="math inline">\(|\beta_k|\)</span>. Define <span class="math display">\[
V_i^k := Y_i - X_{i, -k}^T \beta_{-k}
\]</span> as the residuals from all effects except the <span class="math inline">\(k\)</span>th. The corresponding (conditional) least square estimate is then <span class="math display">\[
\hat{\beta}_k ^\text{ols} := \frac{\sum_{i=1}^N X_{ik} V_i^k}{\sum_{i=1}^N X_{ik}^2},
\]</span> which is used to construct the LASSOplus estimate for the <span class="math inline">\(k\)</span>th element: <span class="math display">\[
\beta_k^\text{plus} | \cdot := \beta_k I\left(\left| \hat{\beta}_k ^\text{ols} \right| \geq \frac{\lambda \sigma_{sp} w_k}{N-1}\right).
\]</span></p>
<p>This threshold ensure that LASSOplus satisfies the Oracple Property.</p>
</section>
<section id="spikeslabgam" class="level3">
<h3 class="anchored" data-anchor-id="spikeslabgam">spikeSlabGAM</h3>
<p>First, start with a GAMM (generalized additive mixed model) <span class="math display">\[
\eta = \eta_0 + X_u\beta_u + \sum\limits_{j=1}^p f_j(x)
\]</span> with model terms <span class="math inline">\(f_j(x) = \left(f_j(x_1), \ldots, f_j(x_n) \right)^T\)</span>, <span class="math inline">\(j=1,\ldots,p\)</span>. These can be constructed with basis functions <span class="math inline">\(B_j\)</span> by <span class="math display">\[
\begin{split}
f_j(x) &amp;= \sum\limits_{k = 1}^{d_j} \beta_{jk}B_{jk}(x) =: B_j \beta_j, \ \text{with} \\
\mathbb{R}^{d_j} \ni \beta_j &amp;\overset{\text{prior}}{\sim} \text{peNMIG}(v_0, w, a_\tau, b_\tau).
\end{split}
\]</span> peNMIG is short for <em>parameter expanded mormal-mixture of inverse Gamma</em> and an extension to the basic idea of the SSVS (as defined above) approach using <em>spike-and-slab</em> priors. Define binary <span class="math inline">\(\gamma_i\)</span> that controls the inclusion of <span class="math inline">\(\beta_i\)</span> in the model. The NMIG prior for a scalar <span class="math inline">\(\alpha\)</span> can then be written as <span class="math display">\[
\begin{split}
\alpha \mid \gamma, \tau^2 &amp;\overset{\text{prior}}{\sim} \mathcal{N}(0, v^2), \ \text{with} \ v^2 = \tau^2 \gamma \\
\gamma \mid w &amp;\overset{\text{prior}}{\sim} w1_{\gamma = 1} + (1-w)1_{\gamma = v_0}, \ \text{with very small} \ v_0&gt;0 \\
\tau^2 &amp;\overset{\text{prior}}{\sim} \Gamma^{-1}\left(a_\tau, b_\tau \right) \\
w  &amp;\overset{\text{prior}}{\sim} \text{Beta}(a_w, b_w)
\end{split}
\]</span> Now the <em>spike</em> part corresponds to the probability of a particular coefficient to be <span class="math inline">\(0\)</span> (i.e.&nbsp;the variance <span class="math inline">\(v^2\)</span> is very small if <span class="math inline">\(\gamma = v_0\)</span>) and vice versa the <em>slab</em> part is the prior distribution of the regression coefficients with <span class="math inline">\(\gamma = 1\)</span>.</p>
<p><span class="citation" data-cites="scheipl2011">(<a href="#ref-scheipl2011" role="doc-biblioref">Scheipl 2011</a>)</span> mentioned that this NMIG prior is unsuited for the simultaneous selection of coefficient vectors. The <em>parameter expanded</em> NMIG is a solution strategy: Set <span class="math inline">\(\beta_i := \alpha_i \xi_i\)</span> with <span class="math display">\[
\begin{split}
\alpha_i &amp;\overset{\text{prior}}{\sim} \text{NMIG}(v_o, w, a_\tau, b_\tau) \ \text{and} \\
\xi_{ik} &amp;\overset{\text{prior}}{\sim} \mathcal{N}(m_{ik}, 1), \ m_{ik} \sim \mathcal{U}(\lbrace -1, 1 \rbrace)
\end{split}
\]</span> The scalar <span class="math inline">\(\alpha_i\)</span> can be interpreted as ‘importance’ of the <span class="math inline">\(i\)</span>th model term and the vector <span class="math inline">\(\xi_i\)</span> ‘distributes’ <span class="math inline">\(\alpha_i\)</span> across entries of <span class="math inline">\(\beta_i\)</span>. The default settings are <span class="math inline">\(a_\tau = 5,\ b_\tau = 24,\ v_0 = 2.5 \cdot 10^{-4},\ a_w = b_w = 1\)</span>. The implementation is done via a MCMC sampler for peNMIG.</p>
</section>
</section>
</section>
<section id="references" class="level1">
<h1>References</h1>
<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-Dab2019" class="csl-entry" role="listitem">
Dablander, Fabian. 2019. <span>“Variable Selection Using Gibbs Sampling.”</span> <a href="https://fabiandablander.com/r/Spike-and-Slab.html">https://fabiandablander.com/r/Spike-and-Slab.html</a>.
</div>
<div id="ref-danilevicz2024" class="csl-entry" role="listitem">
Danilevicz, Ian Meneghel, Valdério Anselmo Reisen, and Pascal Bondon. 2024. <span>“Expectile and M-Quantile Regression for Panel Data.”</span> <em>Statistics and Computing</em> 34 (3). <a href="https://doi.org/10.1007/s11222-024-10396-7">https://doi.org/10.1007/s11222-024-10396-7</a>.
</div>
<div id="ref-RN24" class="csl-entry" role="listitem">
Deshpande, Ved, Dipak K. Dey, and Elizabeth D. Schifano. 2019. <span>“Variable Selection for Correlated Bivariate Mixed Outcomes Using Penalized Generalized Estimating Equations.”</span> Journal Article. <em>Statistics and Its Interface</em> 12 (2): 265–74. <a href="https://doi.org/10.4310/SII.2019.v12.n2.a7">https://doi.org/10.4310/SII.2019.v12.n2.a7</a>.
</div>
<div id="ref-RN19" class="csl-entry" role="listitem">
Garrett M. Fitzmaurice, James H. Ware, Nan M. Laird. 2011. <em>Applied Longitudinal Analysis</em>. Book. Wiley Series in Probability and Statistics. <a href="https://doi.org/10.1002/9781119513469">https://doi.org/10.1002/9781119513469</a>.
</div>
<div id="ref-groll2012" class="csl-entry" role="listitem">
Groll, Andreas, and Gerhard Tutz. 2012. <span>“Variable Selection for Generalized Linear Mixed Models by L 1-Penalized Estimation.”</span> <em>Statistics and Computing</em> 24 (2): 137–54. <a href="https://doi.org/10.1007/s11222-012-9359-z">https://doi.org/10.1007/s11222-012-9359-z</a>.
</div>
<div id="ref-hui2017" class="csl-entry" role="listitem">
Hui, Francis K. C., Samuel Müller, and A. H. Welsh. 2017. <span>“Joint Selection in Mixed Models Using Regularized PQL.”</span> <em>Journal of the American Statistical Association</em> 112 (519): 1323–33. <a href="https://doi.org/10.1080/01621459.2016.1215989">https://doi.org/10.1080/01621459.2016.1215989</a>.
</div>
<div id="ref-PN2015" class="csl-entry" role="listitem">
Perrakis, Konstantinos, and Ioannis Ntzoufras. 2015. <span>“Stochastic Search Variable Selection (SSVS).”</span> In <em>Wiley StatsRef: Statistics Reference Online</em>, 1–6. John Wiley &amp; Sons, Ltd. https://doi.org/<a href="https://doi.org/10.1002/9781118445112.stat07829">https://doi.org/10.1002/9781118445112.stat07829</a>.
</div>
<div id="ref-ratkovic2017" class="csl-entry" role="listitem">
Ratkovic, Marc, and Dustin Tingley. 2017. <span>“Sparse Estimation and Uncertainty with Application to Subgroup Analysis.”</span> <em>Political Analysis</em> 25 (1): 1–40. <a href="https://doi.org/10.1017/pan.2016.14">https://doi.org/10.1017/pan.2016.14</a>.
</div>
<div id="ref-scheipl2011" class="csl-entry" role="listitem">
Scheipl, Fabian. 2011. <span>“spikeSlabGAM: Bayesian Variable Selection, Model Choice and Regularization for Generalized Additive Mixed Models in r.”</span> <em>Journal of Statistical Software</em> 43 (14): 1–24. <a href="https://doi.org/10.18637/jss.v043.i14">https://doi.org/10.18637/jss.v043.i14</a>.
</div>
<div id="ref-taavoni2021" class="csl-entry" role="listitem">
Taavoni, M., and M. Arashi. 2021. <span>“High-Dimensional Generalized Semiparametric Model for Longitudinal Data.”</span> <em>Statistics</em> 55 (4): 831–50. <a href="https://doi.org/10.1080/02331888.2021.1977304">https://doi.org/10.1080/02331888.2021.1977304</a>.
</div>
<div id="ref-RN18" class="csl-entry" role="listitem">
Vaughan, G., R. Aseltine, K. Chen, and J. Yan. 2017. <span>“Stagewise Generalized Estimating Equations with Grouped Variables.”</span> Journal Article. <em>Biometrics</em> 73 (4): 1332–42. <a href="https://doi.org/10.1111/biom.12669">https://doi.org/10.1111/biom.12669</a>.
</div>
<div id="ref-RN16" class="csl-entry" role="listitem">
Wang, L., J. Zhou, and A. Qu. 2012. <span>“Penalized Generalized Estimating Equations for High-Dimensional Longitudinal Data Analysis.”</span> Journal Article. <em>Biometrics</em> 68 (2): 353–60. <a href="https://doi.org/10.1111/j.1541-0420.2011.01678.x">https://doi.org/10.1111/j.1541-0420.2011.01678.x</a>.
</div>
<div id="ref-yang2022" class="csl-entry" role="listitem">
Yang, Luoying, and Tong Tong Wu. 2022. <span>“Model-Based Clustering of High-Dimensional Longitudinal Data via Regularization.”</span> <em>Biometrics</em> 79 (2): 761–74. <a href="https://doi.org/10.1111/biom.13672">https://doi.org/10.1111/biom.13672</a>.
</div>
<div id="ref-RN14" class="csl-entry" role="listitem">
Zu, Tianhai, Heng Lian, Brittany Green, and Yan Yu. 2022. <span>“Ultra-High Dimensional Quantile Regression for Longitudinal Data: An Application to Blood Pressure Analysis.”</span> Journal Article. <em>Journal of the American Statistical Association</em> 118 (541): 97–108. <a href="https://doi.org/10.1080/01621459.2022.2128806">https://doi.org/10.1080/01621459.2022.2128806</a>.
</div>
</div>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>